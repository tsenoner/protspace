{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d29209",
   "metadata": {},
   "source": [
    "# üî¨ Interactive Pfam & Clan Explorer\n",
    "\n",
    "\n",
    "Welcome! This notebook lets you explore protein families (Pfam) and clans using protein embeddings and visualization with [ProtSpace](https://github.com/tsenoner/protspace).\n",
    "\n",
    "**Features:**\n",
    "\n",
    "1. **Setup:** Install libraries and set up environment\n",
    "2. **Download:** Get necessary data files\n",
    "3. **Select:** Choose up to 10 Pfam families or clans\n",
    "4. **Extract:** Get protein embeddings\n",
    "5. **Generate:** Create visualization with PCA, UMAP, or PaCMAP\n",
    "6. **Visualize:** Launch ProtSpace to explore the embedding space interactively\n",
    "\n",
    "**Usage:**\n",
    "* Run cells sequentially (‚ñ∂Ô∏è or Shift+Enter)\n",
    "* Code is hidden by default for clarity. Double-click cell titles to view code if needed.\n",
    "* Follow instructions in each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f1cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. üì¶ Setup Environment (~ 2 min) { display-mode: \"form\" }\n",
    "# @markdown Run this cell to install required libraries and create data directories.\n",
    "# @markdown Output is hidden, but a success message will appear upon completion.\n",
    "# ---\n",
    "\n",
    "# --- Imports ---\n",
    "import base64\n",
    "import csv\n",
    "import json\n",
    "import importlib.util\n",
    "import os\n",
    "import subprocess\n",
    "import traceback\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib.colors import to_hex\n",
    "from tqdm.notebook import tqdm\n",
    "from ipywidgets import (\n",
    "    Accordion,\n",
    "    Button,\n",
    "    Checkbox,\n",
    "    Dropdown,\n",
    "    FloatSlider,\n",
    "    IntSlider,\n",
    "    Layout,\n",
    "    HBox,\n",
    "    HTML,\n",
    "    Output,\n",
    "    Select,\n",
    "    Text,\n",
    "    VBox,\n",
    "    widgets,\n",
    ")\n",
    "\n",
    "# Import ProtSpace for visualization\n",
    "if importlib.util.find_spec(\"protspace\") is None:\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"protspace[frontend]\"],\n",
    "        stdout=subprocess.DEVNULL,\n",
    "        stderr=subprocess.DEVNULL,\n",
    "    )\n",
    "from protspace.app import ProtSpace\n",
    "\n",
    "# --- Create Data Directories using Pathlib ---\n",
    "parent_data_dir = Path(\"../data\")\n",
    "if parent_data_dir.exists():\n",
    "    data_dir = parent_data_dir\n",
    "else:\n",
    "    data_dir = Path(\"data\")\n",
    "raw_data_dir = data_dir / \"raw\"\n",
    "explore_data_dir = data_dir / \"explore\"\n",
    "raw_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "explore_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- Global variable to store path of the latest generated/styled JSON ---\n",
    "generated_json_path = None\n",
    "\n",
    "print(\"‚úÖ Setup complete. Libraries installed and directories created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe940d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. üìÇ Download Data Files (~ 1 min) { display-mode: \"form\" }\n",
    "# @markdown This cell downloads these required files if they don't exist:\n",
    "# @markdown - UniProt-Pfam Mapping\n",
    "# @markdown - Pfam Clan Information\n",
    "# @markdown - UniProt Swiss-Prot Embeddings (large file)\n",
    "# ---\n",
    "\n",
    "# Assumes raw_data_dir and explore_data_dir are defined in Cell 1\n",
    "pfam_file_path = raw_data_dir / \"uniprot_pfam.tsv\"\n",
    "sprot_file_path = raw_data_dir / \"uniprot_sprot.h5\"\n",
    "pfam_clans_path = raw_data_dir / \"Pfam-A.clans.tsv\"\n",
    "\n",
    "\n",
    "# Function to download a file using wget with progress\n",
    "def download_file_wget(url, output_path: Path, description):\n",
    "    if not output_path.exists():\n",
    "        print(f\"‚è≥ Downloading {description}...\")\n",
    "        try:\n",
    "            # Use wget for efficient download and progress bar\n",
    "            process = subprocess.run(\n",
    "                [\n",
    "                    \"wget\",\n",
    "                    url,\n",
    "                    \"-O\",\n",
    "                    str(output_path),\n",
    "                ],\n",
    "                check=True,\n",
    "                # Capture stderr to check progress, suppress stdout\n",
    "                stderr=subprocess.PIPE,\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                text=True,\n",
    "                encoding=\"utf-8\",  # Specify encoding\n",
    "            )\n",
    "            # Check file existence as primary success indicator after command runs\n",
    "            if output_path.exists() and output_path.stat().st_size > 0:\n",
    "                print(f\"‚úÖ Successfully downloaded {description}\")\n",
    "                return True\n",
    "            else:\n",
    "                # Provide more specific error based on stderr if available\n",
    "                err_msg = process.stderr if process.stderr else \"Unknown reason.\"\n",
    "                print(\n",
    "                    f\"‚ùå Error downloading {description}: 'wget' completed but file not found or empty.\"\n",
    "                )\n",
    "                print(f\"Stderr: {err_msg}\")\n",
    "                # Attempt cleanup if file exists but is empty or invalid\n",
    "                if output_path.exists():\n",
    "                    try:\n",
    "                        output_path.unlink()\n",
    "                    except OSError:\n",
    "                        pass\n",
    "                return False\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\n",
    "                \"‚ùå Error: 'wget' command not found. Please ensure wget is installed and in your system's PATH.\"\n",
    "            )\n",
    "            return False\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(\n",
    "                f\"‚ùå Error downloading {description} with wget (return code {e.returncode}):\"\n",
    "            )\n",
    "            print(f\"Stderr:\\n{e.stderr}\")\n",
    "            # Clean up potentially incomplete file\n",
    "            if output_path.exists():\n",
    "                try:\n",
    "                    output_path.unlink()\n",
    "                except OSError:\n",
    "                    pass\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå An unexpected error occurred during download: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"‚úÖ {description} already exists locally.\")\n",
    "        return True\n",
    "\n",
    "\n",
    "# List of files to download\n",
    "files_to_download = [\n",
    "    {\n",
    "        \"url\": \"https://nextcloud.in.tum.de/index.php/s/9q3kefKeND8rkQ8/download\",\n",
    "        \"path\": pfam_file_path,\n",
    "        \"description\": \"UniProt-Pfam mapping\",\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://nextcloud.in.tum.de/index.php/s/P2icGkHy5Msgw2y/download\",\n",
    "        \"path\": pfam_clans_path,\n",
    "        \"description\": \"Pfam clans information\",\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://nextcloud.in.tum.de/index.php/s/CsBBsz4cJ3zwtHa/download\",\n",
    "        \"path\": sprot_file_path,\n",
    "        \"description\": \"UniProt Swiss-Prot embeddings (large file)\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Download all files\n",
    "all_successful = True\n",
    "print(\"--- Starting Data Download ---\")\n",
    "for file_info in files_to_download:\n",
    "    file_path_obj = Path(file_info[\"path\"])\n",
    "    success = download_file_wget(\n",
    "        file_info[\"url\"], file_path_obj, file_info[\"description\"]\n",
    "    )\n",
    "    if not success:\n",
    "        all_successful = False\n",
    "\n",
    "# Verify completion and show file sizes\n",
    "if all_successful:\n",
    "    print(\"\\n--- Data Verification ---\")\n",
    "    total_size_mb = 0\n",
    "    all_files_found = True\n",
    "    for file_info in files_to_download:\n",
    "        path_obj = Path(file_info[\"path\"])\n",
    "        if path_obj.exists():\n",
    "            try:\n",
    "                size_bytes = path_obj.stat().st_size\n",
    "                if size_bytes > 0:\n",
    "                    size_mb = size_bytes / (1024 * 1024)\n",
    "                    print(f\"  ‚Ä¢ {path_obj.name}: {size_mb:.2f} MB\")\n",
    "                    total_size_mb += size_mb\n",
    "                else:\n",
    "                    print(f\"  ‚Ä¢ {path_obj.name}: ‚ö†Ô∏è File exists but is empty!\")\n",
    "                    all_files_found = False\n",
    "            except OSError as e:\n",
    "                print(f\"  ‚Ä¢ {path_obj.name}: ‚ö†Ô∏è Error checking file size: {e}\")\n",
    "                all_files_found = False\n",
    "        else:\n",
    "            print(f\"  ‚Ä¢ {path_obj.name}: ‚ö†Ô∏è File not found after download attempt!\")\n",
    "            all_files_found = False\n",
    "\n",
    "    if all_files_found:\n",
    "        print(\n",
    "            f\"\\n‚úÖ All required data files are present and valid. Total size: {total_size_mb:.2f} MB.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"\\n‚ö†Ô∏è Some critical data files are missing or invalid. Please check download errors above and try running this cell again.\"\n",
    "        )\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Some files could not be downloaded. Please check the errors above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9e28b7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @title 3. ‚ú® Initialize Data Lookup & Select Families/Clans { display-mode: \"form\" }\n",
    "# @markdown Lookup system for Pfam families/clans selection.\n",
    "# @markdown\n",
    "# @markdown **Quick Guide:**\n",
    "# @markdown 1. Select search type (Pfam/Clans)\n",
    "# @markdown 2. Search results (optional)\n",
    "# @markdown 3. Select from list *(three families preselected)*\n",
    "# @markdown 4. Add to your selections (max 10)\n",
    "# @markdown 5. Use \"Clear All\" to reset\n",
    "# @markdown 6. View your selections in the table below\n",
    "# ---\n",
    "\n",
    "# --- ProteinPfamClanLookup Class Definition ---\n",
    "class ProteinPfamClanLookup:\n",
    "    \"\"\"Handles efficient lookups between proteins, Pfam families, and clans.\"\"\"\n",
    "\n",
    "    def __init__(self, protein_pfam_path, pfam_clan_path=None):\n",
    "        protein_pfam_file = Path(protein_pfam_path)\n",
    "        pfam_clan_file = Path(pfam_clan_path) if pfam_clan_path else None\n",
    "\n",
    "        # --- Initialize protein-Pfam relationships ---\n",
    "        if not protein_pfam_file.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Could not find protein-Pfam mapping file at {protein_pfam_file}. Ensure it was downloaded correctly.\"\n",
    "            )\n",
    "        try:\n",
    "            schema_overrides = {\"Entry\": pl.Utf8, \"Pfam\": pl.Utf8}\n",
    "            df = pl.read_csv(\n",
    "                protein_pfam_file, separator=\"\\t\", schema_overrides=schema_overrides\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                f\"Could not read protein-Pfam mapping file {protein_pfam_file}. Error: {e}\"\n",
    "            )\n",
    "\n",
    "        # Process protein-Pfam pairs using Polars\n",
    "        pairs_df = (\n",
    "            df.with_columns(\n",
    "                pl.col(\"Pfam\").fill_null(\"\").cast(pl.Utf8)\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.col(\"Pfam\").str.strip_chars(\";\").str.split(\";\").alias(\"Pfam_list\")\n",
    "            )\n",
    "            .select([\"Entry\", \"Pfam_list\"])\n",
    "            .explode(\"Pfam_list\")\n",
    "            .filter(pl.col(\"Pfam_list\") != \"\")\n",
    "        )\n",
    "\n",
    "        # Create protein -> {pfam1, pfam2,...}\n",
    "        protein_groups = pairs_df.group_by(\"Entry\").agg(\n",
    "            pl.col(\"Pfam_list\").unique()\n",
    "        )\n",
    "        self.protein_to_pfams = {\n",
    "            row[\"Entry\"]: set(row[\"Pfam_list\"])\n",
    "            for row in protein_groups.iter_rows(named=True)\n",
    "        }\n",
    "\n",
    "        # Create pfam -> {protein1, protein2,...}\n",
    "        pfam_groups = pairs_df.group_by(\"Pfam_list\").agg(\n",
    "            pl.col(\"Entry\").unique()\n",
    "        )\n",
    "        self.pfam_to_proteins = {\n",
    "            row[\"Pfam_list\"]: set(row[\"Entry\"])\n",
    "            for row in pfam_groups.iter_rows(named=True)\n",
    "        }\n",
    "\n",
    "        # --- Initialize Pfam-clan relationships ---\n",
    "        self.clan_to_pfams = {}\n",
    "        self.pfam_to_clan = {}\n",
    "        self.clan_details = {}\n",
    "\n",
    "        if pfam_clan_file and pfam_clan_file.exists():\n",
    "            try:\n",
    "                clan_schema_overrides = {\n",
    "                    \"pfam_id\": pl.Utf8,\n",
    "                    \"clan_id\": pl.Utf8,\n",
    "                    \"clan_name\": pl.Utf8,\n",
    "                }\n",
    "                clan_df = pl.read_csv(\n",
    "                    pfam_clan_file,\n",
    "                    separator=\"\\t\",\n",
    "                    has_header=False,\n",
    "                    new_columns=[\n",
    "                        \"pfam_id\",\n",
    "                        \"clan_id\",\n",
    "                        \"clan_name\",\n",
    "                        \"pfam_name\",\n",
    "                        \"pfam_description\",\n",
    "                    ],\n",
    "                    schema_overrides=clan_schema_overrides,\n",
    "                ).filter(\n",
    "                    pl.col(\"clan_id\").is_not_null() & (pl.col(\"clan_id\") != \"\")\n",
    "                )\n",
    "\n",
    "                # Create clan -> {pfam1, pfam2,...} \n",
    "                clan_groups = clan_df.group_by(\"clan_id\").agg(\n",
    "                    pl.col(\"pfam_id\").unique().alias(\"pfams\"),\n",
    "                    pl.first(\"clan_name\").alias(\"name\"),\n",
    "                )\n",
    "                self.clan_to_pfams = {\n",
    "                    row[\"clan_id\"]: set(row[\"pfams\"])\n",
    "                    for row in clan_groups.iter_rows(named=True)\n",
    "                }\n",
    "                self.clan_details = {\n",
    "                    row[\"clan_id\"]: {\n",
    "                        \"name\": row[\"name\"],\n",
    "                        \"pfam_count\": len(row[\"pfams\"]),\n",
    "                    }\n",
    "                    for row in clan_groups.iter_rows(named=True)\n",
    "                }\n",
    "\n",
    "                # Create pfam -> clan dictionary\n",
    "                self.pfam_to_clan = {\n",
    "                    row[\"pfam_id\"]: row[\"clan_id\"]\n",
    "                    for row in clan_df.select([\"pfam_id\", \"clan_id\"]).iter_rows(\n",
    "                        named=True\n",
    "                    )\n",
    "                    if row[\"clan_id\"]\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Warning: Could not read or process Pfam clan file at {pfam_clan_file}. Clan features might be incomplete. Error: {e}\"\n",
    "                )\n",
    "        elif pfam_clan_file:\n",
    "            print(\n",
    "                f\"Warning: Pfam clan file specified but not found at {pfam_clan_file}. Clan features will be unavailable.\"\n",
    "            )\n",
    "\n",
    "    # --- Lookup Methods ---\n",
    "    def get_pfams_for_protein(self, protein):\n",
    "        return self.protein_to_pfams.get(protein, set())\n",
    "\n",
    "    def get_proteins_for_pfam(self, pfam):\n",
    "        return self.pfam_to_proteins.get(pfam, set())\n",
    "\n",
    "    def get_all_pfams(self):\n",
    "        return set(self.pfam_to_proteins.keys())\n",
    "\n",
    "    def get_all_clans(self):\n",
    "        return list(self.clan_to_pfams.keys())\n",
    "\n",
    "    def get_pfams_for_clan(self, clan_id):\n",
    "        return self.clan_to_pfams.get(clan_id, set())\n",
    "\n",
    "    def get_clan_for_pfam(self, pfam_id):\n",
    "        return self.pfam_to_clan.get(pfam_id)\n",
    "\n",
    "    def get_clan_details(self, clan_id):\n",
    "        return self.clan_details.get(\n",
    "            clan_id,\n",
    "            {\"name\": \"Unknown\", \"pfam_count\": len(self.get_pfams_for_clan(clan_id))},\n",
    "        )\n",
    "\n",
    "    def get_proteins_for_clan(self, clan_id):\n",
    "        proteins = set()\n",
    "        for pfam_id in self.get_pfams_for_clan(clan_id):\n",
    "            proteins.update(self.get_proteins_for_pfam(pfam_id))\n",
    "        return proteins\n",
    "\n",
    "    def get_clans_for_protein(self, protein):\n",
    "        clans = set()\n",
    "        for pfam_id in self.get_pfams_for_protein(protein):\n",
    "            clan_id = self.get_clan_for_pfam(pfam_id)\n",
    "            if clan_id:\n",
    "                clans.add(clan_id)\n",
    "        return clans\n",
    "\n",
    "\n",
    "# --- Initialize Lookup ---\n",
    "lookup_status_output = Output()\n",
    "pfam_options = {}\n",
    "clan_options = {}\n",
    "lookup = None\n",
    "initialization_message = \"\"  # Store the final message\n",
    "\n",
    "with lookup_status_output:  # Capture tqdm output here temporarily\n",
    "    try:\n",
    "        lookup = ProteinPfamClanLookup(pfam_file_path, pfam_clans_path)\n",
    "\n",
    "        # Prepare options for Pfam dropdown/selector with counts\n",
    "        all_pfams = sorted(list(lookup.get_all_pfams()))\n",
    "        # Run tqdm outside the dict comprehension for cleaner progress\n",
    "        pfam_proteins_counts = {\n",
    "            pfam: len(lookup.get_proteins_for_pfam(pfam))\n",
    "            for pfam in tqdm(\n",
    "                all_pfams, desc=\"Loading Pfam options\", leave=False, mininterval=0.5\n",
    "            )\n",
    "        }\n",
    "        pfam_options = {\n",
    "            f\"{pfam} ({count} proteins)\": pfam\n",
    "            for pfam, count in pfam_proteins_counts.items()\n",
    "        }\n",
    "\n",
    "        # Prepare options for Clan dropdown with counts\n",
    "        all_clans = sorted(lookup.get_all_clans())\n",
    "        clan_proteins_counts = {\n",
    "            clan: len(lookup.get_proteins_for_clan(clan))\n",
    "            for clan in tqdm(\n",
    "                all_clans, desc=\"Loading Clan options\", leave=False, mininterval=0.5\n",
    "            )\n",
    "        }\n",
    "        clan_options = {}\n",
    "        for clan, protein_count in clan_proteins_counts.items():\n",
    "            details = lookup.get_clan_details(clan)\n",
    "            pfam_count = details[\"pfam_count\"]\n",
    "            clan_options[f\"{clan} ({pfam_count} Pfams, {protein_count} proteins)\"] = (\n",
    "                clan\n",
    "            )\n",
    "\n",
    "        initialization_message = f\"‚úÖ Lookup initialized. Found {len(all_pfams)} Pfam families and {len(all_clans)} clans.\"\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        initialization_message = f\"‚ùå Error initializing lookup: {e}\\n   Please ensure the data files were downloaded successfully in Step 2.\"\n",
    "    except Exception as e:\n",
    "        initialization_message = (\n",
    "            f\"‚ùå An unexpected error occurred during lookup initialization: {e}\"\n",
    "        )\n",
    "\n",
    "# --- Define Widgets ---\n",
    "search_type = Dropdown(\n",
    "    options=[\"Pfam Families\", \"Clans\"],\n",
    "    value=\"Pfam Families\",\n",
    "    description=\"Search by:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")\n",
    "search_field = Text(\n",
    "    placeholder=\"Filter by ID (e.g., PF00067 or CL0001)...\",\n",
    "    description=\"Filter:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"60%\"},\n",
    ")\n",
    "selector = Select(\n",
    "    options=[],\n",
    "    value=None,\n",
    "    description=\"Select:\",\n",
    "    rows=10,\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"95%\"},\n",
    ")\n",
    "add_button = Button(description=\"Add Selected\", button_style=\"info\", icon=\"plus\")\n",
    "clear_button = Button(description=\"Clear All\", button_style=\"warning\", icon=\"trash\")\n",
    "selected_items_display = HTML(value=\"<p>No items selected yet.</p>\")\n",
    "selected_items_summary = HTML(value=\"\")\n",
    "status_display = HTML()\n",
    "\n",
    "# --- Global state for selections ---\n",
    "selected_pfams = [\"PF00061\", \"PF00067\", \"PF00077\"]\n",
    "selected_clans = [\"CL0001\", \"CL0092\", \"CL0240\"]\n",
    "current_mode = \"Pfam Families\"\n",
    "\n",
    "\n",
    "# --- Widget Logic Functions ---\n",
    "def get_total_selected_proteins():\n",
    "    \"\"\"Calculate total unique proteins for the current selection.\"\"\"\n",
    "    if not lookup:\n",
    "        return 0\n",
    "    total_proteins = set()\n",
    "    items = selected_pfams if current_mode == \"Pfam Families\" else selected_clans\n",
    "    getter = (\n",
    "        lookup.get_proteins_for_pfam\n",
    "        if current_mode == \"Pfam Families\"\n",
    "        else lookup.get_proteins_for_clan\n",
    "    )\n",
    "    for item_id in items:\n",
    "        total_proteins.update(getter(item_id))\n",
    "    return len(total_proteins)\n",
    "\n",
    "\n",
    "def update_display():\n",
    "    \"\"\"Update the HTML table showing selected items and the summary.\"\"\"\n",
    "    if not lookup:\n",
    "        return\n",
    "\n",
    "    target_list = selected_pfams if current_mode == \"Pfam Families\" else selected_clans\n",
    "    item_type_plural = \"Pfam Families\" if current_mode == \"Pfam Families\" else \"Clans\"\n",
    "    limit = 10\n",
    "\n",
    "    # --- Build DataFrame for HTML Table ---\n",
    "    if target_list:\n",
    "        data = []\n",
    "        if current_mode == \"Pfam Families\":\n",
    "            for pfam in target_list:\n",
    "                proteins = lookup.get_proteins_for_pfam(pfam)\n",
    "                clan = lookup.get_clan_for_pfam(pfam) or \"N/A\"\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"Pfam Family\": pfam,\n",
    "                        \"Proteins\": f\"{len(proteins):,}\",\n",
    "                        \"Clan\": clan,\n",
    "                    }\n",
    "                )\n",
    "            df = pd.DataFrame(data)\n",
    "            display_title = f\"Selected Pfam Families ({len(target_list)}/{limit})\"\n",
    "        else:  # Clans mode\n",
    "            for clan in target_list:\n",
    "                proteins = lookup.get_proteins_for_clan(clan)\n",
    "                details = lookup.get_clan_details(clan)\n",
    "                pfam_count = details[\"pfam_count\"]\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"Clan ID\": clan,\n",
    "                        \"Pfam Families\": pfam_count,\n",
    "                        \"Proteins\": f\"{len(proteins):,}\",\n",
    "                    }\n",
    "                )\n",
    "            df = pd.DataFrame(data)\n",
    "            display_title = f\"Selected Clans ({len(target_list)}/{limit})\"\n",
    "\n",
    "        # Convert DataFrame to HTML\n",
    "        selected_items_display.value = f\"<h4>{display_title}:</h4>{df.to_html(index=False, classes='table table-striped table-sm', border=0, justify='left')}\"\n",
    "    else:\n",
    "        selected_items_display.value = f\"<p>No {item_type_plural.lower()} selected.</p>\"\n",
    "\n",
    "    # --- Update Summary (Total proteins + Warning) ---\n",
    "    total_proteins = get_total_selected_proteins()\n",
    "    summary_html = f\"<p style='margin-top: 10px;'><b>Total unique proteins in selection: {total_proteins:,}</b></p>\"\n",
    "    if total_proteins > 20000:\n",
    "        summary_html += '<p style=\"color: orange;\">‚ö†Ô∏è <b>Warning:</b> Selecting over 20,000 proteins may lead to slow performance in subsequent steps (Extraction, Generation, Visualization).</p>'\n",
    "    selected_items_summary.value = summary_html\n",
    "\n",
    "    status_display.value = \"\"\n",
    "\n",
    "\n",
    "# --- Other Widget Callbacks (Largely Unchanged Logic) ---\n",
    "def update_selector_options():\n",
    "    if not lookup:\n",
    "        return\n",
    "    global current_mode\n",
    "    search_term = search_field.value.strip().lower()\n",
    "    options_dict = pfam_options if current_mode == \"Pfam Families\" else clan_options\n",
    "    desc = \"Select Pfam:\" if current_mode == \"Pfam Families\" else \"Select Clan:\"\n",
    "\n",
    "    if search_term:\n",
    "        filtered_options = {\n",
    "            k: v for k, v in options_dict.items() if search_term in k.lower()\n",
    "        }\n",
    "        selector.options = list(filtered_options.keys())\n",
    "    else:\n",
    "        selector.options = list(options_dict.keys())\n",
    "    selector.description = desc\n",
    "    selector.value = None  # Reset selection after filtering\n",
    "\n",
    "\n",
    "def on_search_type_change(change):\n",
    "    global current_mode  # Ensure we modify the global variable\n",
    "    if change[\"new\"] != change[\"old\"]:\n",
    "        current_mode = change[\"new\"]  # Update mode state\n",
    "        search_field.value = \"\"\n",
    "        update_selector_options()\n",
    "        update_display()  # Update selection list title and summary\n",
    "\n",
    "\n",
    "def filter_items(change):\n",
    "    update_selector_options()\n",
    "\n",
    "\n",
    "def add_selected(button):\n",
    "    global selected_pfams, selected_clans  # Ensure modification of globals\n",
    "    selected_key = selector.value\n",
    "    if not lookup or not selected_key:\n",
    "        status_display.value = (\n",
    "            '<p style=\"color: orange;\">‚ö†Ô∏è Please select an item from the list first.</p>'\n",
    "        )\n",
    "        return\n",
    "\n",
    "    options_dict = pfam_options if current_mode == \"Pfam Families\" else clan_options\n",
    "    item_id = options_dict[selected_key]\n",
    "\n",
    "    target_list = selected_pfams if current_mode == \"Pfam Families\" else selected_clans\n",
    "    item_type = \"Pfam family\" if current_mode == \"Pfam Families\" else \"clan\"\n",
    "    limit = 10\n",
    "\n",
    "    if item_id in target_list:\n",
    "        status_display.value = f'<p style=\"color: orange;\">‚ö†Ô∏è This {item_type} ({item_id}) is already selected.</p>'\n",
    "        return\n",
    "\n",
    "    if len(target_list) >= limit:\n",
    "        status_display.value = f'<p style=\"color: red;\">‚ùå Maximum limit of {limit} {item_type}s reached.</p>'\n",
    "        return\n",
    "\n",
    "    target_list.append(item_id)\n",
    "    status_display.value = (\n",
    "        f'<p style=\"color: green;\">‚úÖ Added {item_type}: {item_id}</p>'\n",
    "    )\n",
    "    update_display()  # Refresh list and summary\n",
    "\n",
    "\n",
    "def clear_selections(button):\n",
    "    global selected_pfams, selected_clans  # Ensure modification of globals\n",
    "    item_type = \"Pfam family\" if current_mode == \"Pfam Families\" else \"clan\"\n",
    "    cleared = False\n",
    "    if current_mode == \"Pfam Families\":\n",
    "        if selected_pfams:  # Only clear if list is not empty\n",
    "            selected_pfams = []\n",
    "            cleared = True\n",
    "    else:\n",
    "        if selected_clans:  # Only clear if list is not empty\n",
    "            selected_clans = []\n",
    "            cleared = True\n",
    "\n",
    "    if cleared:\n",
    "        status_display.value = (\n",
    "            f'<p style=\"color: blue;\">‚ÑπÔ∏è All selected {item_type}s cleared.</p>'\n",
    "        )\n",
    "        update_display()\n",
    "\n",
    "\n",
    "# --- Connect Widgets ---\n",
    "if lookup:  # Only connect if lookup initialized successfully\n",
    "    search_type.observe(on_search_type_change, names=\"value\")\n",
    "    search_field.observe(filter_items, names=\"value\")\n",
    "    add_button.on_click(add_selected)\n",
    "    clear_button.on_click(clear_selections)\n",
    "\n",
    "    # --- Initial Population ---\n",
    "    update_selector_options()  # Populate selector initially\n",
    "    update_display()  # Update display with defaults and summary\n",
    "else:\n",
    "    status_display.value = \"<p style='color: red;'>‚ùå Lookup initialization failed. Cannot create selection widgets.</p>\"\n",
    "\n",
    "# --- Display Widgets ---\n",
    "# Display the final initialization message clearly *after* potential tqdm output\n",
    "print(initialization_message)\n",
    "\n",
    "display(\n",
    "    VBox(\n",
    "        [\n",
    "            HBox([search_type, search_field]),\n",
    "            selector,\n",
    "            HBox([add_button, clear_button]),\n",
    "            status_display,  # For add/clear/error messages\n",
    "            HTML(\"<hr>\"),  # Separator\n",
    "            selected_items_display,  # The HTML table for the list\n",
    "            selected_items_summary,  # HTML for total count and warning\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. üìà Extract Embeddings & Generate Metadata { display-mode: \"form\" }\n",
    "# @markdown Extracts protein embeddings for selected Pfam families/clans and creates metadata for ProtSpace.\n",
    "# @markdown\n",
    "# @markdown **Process:**\n",
    "# @markdown 1. Finds proteins for your selection\n",
    "# @markdown 2. Extracts embeddings from source file\n",
    "# @markdown 3. Creates metadata CSV with annotations\n",
    "# @markdown\n",
    "# @markdown **Note:** May take time for large selections. Progress shown. Previously processed selections will be reused.\n",
    "# @markdown\n",
    "# @markdown ---\n",
    "# @markdown Click to extract:\n",
    "# ---\n",
    "\n",
    "# --- Global variables to store results of the latest successful extraction ---\n",
    "last_extraction_dir: Path | None = None\n",
    "last_embedding_path: Path | None = None\n",
    "last_metadata_path: Path | None = None\n",
    "last_selection_mode: str | None = None  # To track if it was Pfam or Clan\n",
    "last_selected_items: list | None = None  # To store the specific list used\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def get_proteins_for_selection(mode, selected_items_list, lookup_obj):\n",
    "    \"\"\"Gets the set of unique protein IDs based on the current selection mode and items.\"\"\"\n",
    "    # This function remains the same as previous version\n",
    "    if not lookup_obj:\n",
    "        return set(), \"Lookup system not initialized.\"\n",
    "    if not selected_items_list:\n",
    "        return set(), f\"No {mode.replace(' Families', '')[:-1]} selected.\"\n",
    "    all_proteins = set()\n",
    "    getter = (\n",
    "        lookup_obj.get_proteins_for_pfam\n",
    "        if mode == \"Pfam Families\"\n",
    "        else lookup_obj.get_proteins_for_clan\n",
    "    )\n",
    "    for item_id in selected_items_list:\n",
    "        all_proteins.update(getter(item_id))\n",
    "    count = len(all_proteins)\n",
    "    item_type_plural = mode.replace(\" Families\", \"\")\n",
    "    msg = f\"Found {count:,} unique proteins across {len(selected_items_list)} selected {item_type_plural}.\"\n",
    "    return all_proteins, msg\n",
    "\n",
    "\n",
    "def save_embeddings_and_metadata(\n",
    "    proteins, selection_mode, selected_items_list, lookup_obj, input_h5_path: Path\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts embeddings, saves them to a new HDF5 file, and generates the metadata CSV.\n",
    "    Returns a dictionary with paths and summary, or None on error.\n",
    "    Updates global variables on success.\n",
    "    \"\"\"\n",
    "    global \\\n",
    "        last_extraction_dir, \\\n",
    "        last_embedding_path, \\\n",
    "        last_metadata_path, \\\n",
    "        last_selection_mode, \\\n",
    "        last_selected_items\n",
    "\n",
    "    if not lookup_obj:\n",
    "        print(\"‚ùå Error: Lookup object is not available.\")\n",
    "        return None\n",
    "    if not proteins:\n",
    "        print(\"‚ùå Error: No proteins provided for extraction.\")\n",
    "        return None\n",
    "    if not input_h5_path.exists():\n",
    "        print(\n",
    "            f\"‚ùå Error: Input embedding file not found at {input_h5_path}. Please ensure Step 2 completed.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    # --- Define Paths ---\n",
    "    identifier = \"_\".join(sorted(selected_items_list))\n",
    "    prefix = \"pfam\" if selection_mode == \"Pfam Families\" else \"clan\"\n",
    "    # explore_data_dir is assumed defined globally (Cell 1)\n",
    "    output_dir = explore_data_dir / f\"{prefix}_{identifier}\"\n",
    "    output_h5_path = output_dir / \"embeddings.h5\"\n",
    "    output_csv_path = output_dir / \"metadata.csv\"\n",
    "    output_meta_path = output_dir / \"run_metadata.txt\"\n",
    "\n",
    "    # --- Check for Existing Output ---\n",
    "    if output_dir.exists() and output_h5_path.exists() and output_csv_path.exists():\n",
    "        print(f\"‚úÖ Output for this exact selection already exists in: {output_dir}\")\n",
    "        last_extraction_dir = output_dir\n",
    "        last_embedding_path = output_h5_path\n",
    "        last_metadata_path = output_csv_path\n",
    "        last_selection_mode = selection_mode\n",
    "        last_selected_items = selected_items_list.copy()\n",
    "        found_count, total_requested_count = (\n",
    "            -1,\n",
    "            -1,\n",
    "        )  # Use -1 to indicate not found in metadata\n",
    "        try:\n",
    "            with open(output_meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    if \"Found proteins with embeddings:\" in line:\n",
    "                        found_count = int(line.split(\":\", 1)[1].strip())\n",
    "                    if \"Total proteins requested:\" in line:\n",
    "                        total_requested_count = int(line.split(\":\", 1)[1].strip())\n",
    "        except Exception:\n",
    "            pass  # Ignore errors reading metadata\n",
    "\n",
    "        missing_count_str = \"N/A\"\n",
    "        if found_count != -1 and total_requested_count != -1:\n",
    "            missing_count_str = f\"{total_requested_count - found_count:,}\"\n",
    "        found_count_str = f\"{found_count:,}\" if found_count != -1 else \"N/A\"\n",
    "\n",
    "        return {\n",
    "            \"output_dir\": output_dir,\n",
    "            \"embedding_path\": output_h5_path,\n",
    "            \"metadata_path\": output_csv_path,\n",
    "            \"total_proteins_requested\": len(proteins),  # Current request size\n",
    "            \"found_proteins\": found_count_str,\n",
    "            \"missing_proteins\": missing_count_str,\n",
    "            \"already_exists\": True,\n",
    "        }\n",
    "\n",
    "    # --- Create Output Directory ---\n",
    "    try:\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    except OSError as e:\n",
    "        print(f\"‚ùå Error creating output directory {output_dir}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # --- Extract Embeddings ---\n",
    "    found_count = 0\n",
    "    missing_proteins_count = 0\n",
    "    print(f\"üîÑ Extracting embeddings for {len(proteins):,} proteins...\")\n",
    "    # Use a set to efficiently track proteins we actually save embeddings for\n",
    "    saved_protein_ids = set()\n",
    "    try:\n",
    "        with (\n",
    "            h5py.File(input_h5_path, \"r\") as in_file,\n",
    "            h5py.File(output_h5_path, \"w\") as out_file,\n",
    "        ):\n",
    "            # Iterate directly over the input protein set for potential efficiency\n",
    "            for protein_id in tqdm(\n",
    "                proteins, desc=\"Reading embeddings\", unit=\"protein\", mininterval=0.5\n",
    "            ):\n",
    "                if protein_id in in_file:\n",
    "                    embedding = in_file[protein_id][:]\n",
    "                    out_file.create_dataset(protein_id, data=embedding)\n",
    "                    found_count += 1\n",
    "                    saved_protein_ids.add(protein_id)  # Track saved proteins\n",
    "                else:\n",
    "                    missing_proteins_count += 1\n",
    "        print(\n",
    "            f\"‚û°Ô∏è Found embeddings for {found_count:,} out of {len(proteins):,} requested proteins.\"\n",
    "        )\n",
    "        if missing_proteins_count > 0:\n",
    "            print(f\"‚ö†Ô∏è Missing embeddings for {missing_proteins_count:,} proteins.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during embedding extraction: {e}\")\n",
    "        if output_h5_path.exists():\n",
    "            try:\n",
    "                output_h5_path.unlink()\n",
    "            except OSError:\n",
    "                pass\n",
    "        if output_dir.exists() and not any(output_dir.iterdir()):\n",
    "            try:\n",
    "                output_dir.rmdir()\n",
    "            except OSError:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "    # --- Generate Metadata CSV ---\n",
    "    # Use the set of proteins actually saved in the H5 file\n",
    "    print(\"üîÑ Generating metadata CSV file...\")\n",
    "    try:\n",
    "        with open(output_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "\n",
    "            if selection_mode == \"Pfam Families\":\n",
    "                csv_writer.writerow(\n",
    "                    [\"identifier\", \"Pfam_Primary\", \"Pfam_Extended\", \"Clan\"]\n",
    "                )\n",
    "                for protein_id in tqdm(\n",
    "                    saved_protein_ids,\n",
    "                    desc=\"Writing Pfam CSV\",\n",
    "                    unit=\"protein\",\n",
    "                    mininterval=0.5,\n",
    "                ):\n",
    "                    all_pfams_for_protein = lookup_obj.get_pfams_for_protein(protein_id)\n",
    "                    protein_selected_pfams = [\n",
    "                        pfam\n",
    "                        for pfam in selected_items_list\n",
    "                        if pfam in all_pfams_for_protein\n",
    "                    ]\n",
    "                    if not protein_selected_pfams:\n",
    "                        continue  # Should not happen if logic is correct\n",
    "                    primary_pfam = protein_selected_pfams[0]\n",
    "                    primary_clan = lookup_obj.get_clan_for_pfam(primary_pfam) or \"N/A\"\n",
    "                    other_pfams = [\n",
    "                        pfam\n",
    "                        for pfam in all_pfams_for_protein\n",
    "                        if pfam not in selected_items_list\n",
    "                    ]\n",
    "                    num_other = len(other_pfams)\n",
    "                    if num_other == 0:\n",
    "                        pfam_extended = primary_pfam\n",
    "                    elif num_other == 1:\n",
    "                        pfam_extended = f\"{primary_pfam} + 1 other\"\n",
    "                    elif num_other == 2:\n",
    "                        pfam_extended = f\"{primary_pfam} + 2 others\"\n",
    "                    else:\n",
    "                        pfam_extended = f\"{primary_pfam} + >2 others\"\n",
    "                    csv_writer.writerow(\n",
    "                        [protein_id, primary_pfam, pfam_extended, primary_clan]\n",
    "                    )\n",
    "\n",
    "            elif selection_mode == \"Clans\":\n",
    "                csv_writer.writerow([\"identifier\", \"Clan_Primary\", \"Pfam_Label\"])\n",
    "                clan_top_pfams = {}\n",
    "                # Pre-calculate top Pfams based on *saved* proteins\n",
    "                for clan in selected_items_list:\n",
    "                    pfams_in_clan = lookup_obj.get_pfams_for_clan(clan)\n",
    "                    pfam_counts = {}\n",
    "                    for protein_id_saved in saved_protein_ids:\n",
    "                        protein_pfams = lookup_obj.get_pfams_for_protein(\n",
    "                            protein_id_saved\n",
    "                        )\n",
    "                        for pfam in protein_pfams:\n",
    "                            if pfam in pfams_in_clan:\n",
    "                                pfam_counts[pfam] = pfam_counts.get(pfam, 0) + 1\n",
    "                    sorted_pfams = sorted(\n",
    "                        pfam_counts.items(), key=lambda item: item[1], reverse=True\n",
    "                    )\n",
    "                    clan_top_pfams[clan] = [pfam for pfam, _ in sorted_pfams[:3]]\n",
    "\n",
    "                for protein_id in tqdm(\n",
    "                    saved_protein_ids,\n",
    "                    desc=\"Writing Clan CSV\",\n",
    "                    unit=\"protein\",\n",
    "                    mininterval=0.5,\n",
    "                ):\n",
    "                    all_pfams_for_protein = lookup_obj.get_pfams_for_protein(protein_id)\n",
    "                    protein_clans_involved = set()\n",
    "                    pfam_clan_map = {}\n",
    "                    for pfam in all_pfams_for_protein:\n",
    "                        clan = lookup_obj.get_clan_for_pfam(pfam)\n",
    "                        if clan in selected_items_list:\n",
    "                            protein_clans_involved.add(clan)\n",
    "                            pfam_clan_map[pfam] = clan\n",
    "                    if not protein_clans_involved:\n",
    "                        continue\n",
    "                    primary_clan = sorted(list(protein_clans_involved))[0]\n",
    "                    pfam_label = f\"{primary_clan}: Other\"  # Default\n",
    "                    for pfam, clan in pfam_clan_map.items():\n",
    "                        if clan == primary_clan and pfam in clan_top_pfams.get(\n",
    "                            primary_clan, []\n",
    "                        ):\n",
    "                            pfam_label = f\"{primary_clan}: {pfam}\"\n",
    "                            break\n",
    "                    csv_writer.writerow([protein_id, primary_clan, pfam_label])\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid selection mode '{selection_mode}' for CSV generation.\"\n",
    "                )\n",
    "\n",
    "        print(\"‚úÖ Metadata CSV generated successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating metadata CSV: {e}\")\n",
    "        # Clean up files if CSV fails\n",
    "        if output_h5_path.exists():\n",
    "            try:\n",
    "                output_h5_path.unlink()\n",
    "            except OSError:\n",
    "                pass\n",
    "        if output_csv_path.exists():\n",
    "            try:\n",
    "                output_csv_path.unlink()\n",
    "            except OSError:\n",
    "                pass\n",
    "        if output_dir.exists() and not any(output_dir.iterdir()):\n",
    "            try:\n",
    "                output_dir.rmdir()\n",
    "            except OSError:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "    # --- Save Run Metadata ---\n",
    "    try:\n",
    "        with open(output_meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Selection Mode: {selection_mode}\\n\")\n",
    "            f.write(f\"Selected Items: {', '.join(selected_items_list)}\\n\")\n",
    "            f.write(\n",
    "                f\"Total proteins requested: {len(proteins)}\\n\"\n",
    "            )  # Original request size\n",
    "            f.write(\n",
    "                f\"Found proteins with embeddings: {found_count}\\n\"\n",
    "            )  # Actual found in H5\n",
    "            f.write(f\"Missing proteins: {missing_proteins_count}\\n\")\n",
    "            f.write(f\"Input Embedding File: {input_h5_path.name}\\n\")\n",
    "            f.write(f\"Output Embedding File: {output_h5_path.name}\\n\")\n",
    "            f.write(f\"Output Metadata File: {output_csv_path.name}\\n\")\n",
    "            f.write(f\"Output Directory: {output_dir}\\n\")\n",
    "            f.write(f\"Created on: {pd.Timestamp.now()}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not save run metadata file {output_meta_path}: {e}\")\n",
    "\n",
    "    # --- Update Global Variables on Success ---\n",
    "    last_extraction_dir = output_dir\n",
    "    last_embedding_path = output_h5_path\n",
    "    last_metadata_path = output_csv_path\n",
    "    last_selection_mode = selection_mode\n",
    "    last_selected_items = selected_items_list.copy()  # Store a copy\n",
    "\n",
    "    # --- Return Summary ---\n",
    "    return {\n",
    "        \"output_dir\": output_dir,\n",
    "        \"embedding_path\": output_h5_path,\n",
    "        \"metadata_path\": output_csv_path,\n",
    "        \"total_proteins_requested\": len(proteins),\n",
    "        \"found_proteins\": found_count,  # Return integer\n",
    "        \"missing_proteins\": missing_proteins_count,  # Return integer\n",
    "        \"already_exists\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Widget Setup ---\n",
    "extract_button = Button(\n",
    "    description=\"Extract Embeddings & Create Metadata\",\n",
    "    button_style=\"primary\",\n",
    "    icon=\"cogs\",\n",
    ")\n",
    "extraction_output = Output()\n",
    "\n",
    "\n",
    "# --- Button Click Handler ---\n",
    "def on_extract_button_click(b):\n",
    "    with extraction_output:\n",
    "        clear_output()  # Clear previous output\n",
    "        print(f\"--- Starting Extraction for {current_mode} ---\")\n",
    "\n",
    "        if not lookup:\n",
    "            print(\n",
    "                \"‚ùå Cannot proceed: Data lookup system failed to initialize in Step 3.\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        target_list = (\n",
    "            selected_pfams if current_mode == \"Pfam Families\" else selected_clans\n",
    "        )\n",
    "        mode_str = current_mode\n",
    "\n",
    "        if not target_list:\n",
    "            item_type = mode_str.replace(\" Families\", \"\")[:-1]  # Pfam or Clan\n",
    "            print(\n",
    "                f\"‚ö†Ô∏è Please select at least one {item_type} in Step 3 before extracting.\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        print(\"1. Identifying target proteins...\")\n",
    "        all_selected_proteins, message = get_proteins_for_selection(\n",
    "            mode_str, target_list, lookup\n",
    "        )\n",
    "        print(f\"   {message}\")\n",
    "\n",
    "        if not all_selected_proteins:\n",
    "            print(\"‚ö†Ô∏è No proteins found for the current selection. Cannot proceed.\")\n",
    "            return\n",
    "        elif len(all_selected_proteins) > 100000:\n",
    "            # Warning printed by get_proteins_for_selection, maybe add time estimate?\n",
    "            print(\n",
    "                f\"   ‚ö†Ô∏è Note: Processing {len(all_selected_proteins):,} proteins may take significant time.\"\n",
    "            )\n",
    "\n",
    "        print(\"\\n2. Processing embeddings and metadata...\")\n",
    "        # sprot_file_path is assumed global (Cell 2)\n",
    "        process_summary = save_embeddings_and_metadata(\n",
    "            all_selected_proteins, mode_str, target_list, lookup, sprot_file_path\n",
    "        )\n",
    "\n",
    "        print(\"\\n--- Extraction Summary ---\")\n",
    "        if process_summary:\n",
    "            # Format numbers from summary for display\n",
    "            found_proteins_val = process_summary[\"found_proteins\"]\n",
    "            requested_val = process_summary[\"total_proteins_requested\"]\n",
    "            missing_val = process_summary[\"missing_proteins\"]\n",
    "            # Use the formatted strings for N/A cases when already_exists is True\n",
    "            found_str = (\n",
    "                found_proteins_val\n",
    "                if isinstance(found_proteins_val, str)\n",
    "                else f\"{found_proteins_val:,}\"\n",
    "            )\n",
    "            missing_str = (\n",
    "                missing_val if isinstance(missing_val, str) else f\"{missing_val:,}\"\n",
    "            )\n",
    "            requested_str = f\"{requested_val:,}\"  # requested should always be int here\n",
    "\n",
    "            if process_summary.get(\"already_exists\", False):\n",
    "                print(\"‚ÑπÔ∏è Result: Found existing data for this selection.\")\n",
    "                print(f\"   Directory: {process_summary['output_dir']}\")\n",
    "                print(f\"   Embeddings: {process_summary['embedding_path'].name}\")\n",
    "                print(f\"   Metadata: {process_summary['metadata_path'].name}\")\n",
    "                # Report counts based on the previously found data\n",
    "                print(\n",
    "                    f\"   Proteins Found (in existing data): {found_str} / {process_summary.get('total_proteins_requested', 'N/A'):,} originally requested.\"\n",
    "                )\n",
    "            else:\n",
    "                print(\"‚úÖ Result: Extraction and metadata generation successful!\")\n",
    "                print(f\"   Directory: {process_summary['output_dir']}\")\n",
    "                print(f\"   Embeddings: {process_summary['embedding_path'].name}\")\n",
    "                print(f\"   Metadata: {process_summary['metadata_path'].name}\")\n",
    "                print(f\"   Proteins Found: {found_str} / {requested_str} requested.\")\n",
    "                print(f\"   Proteins Missing: {missing_str}\")\n",
    "\n",
    "            print(\"\\nüéâ Ready for Step 5: Generate Visualization JSON.\")\n",
    "        else:\n",
    "            print(\"‚ùå Extraction failed. Please check the error messages above.\")\n",
    "\n",
    "\n",
    "# --- Connect Button ---\n",
    "extract_button.on_click(on_extract_button_click)\n",
    "\n",
    "# --- Display ---\n",
    "display(extract_button)\n",
    "display(extraction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8115be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. üìä Generate ProtSpace Visualization JSON { display-mode: \"form\" }\n",
    "# @markdown Runs dimensionality reduction on embeddings and creates visualization files for ProtSpace.\n",
    "# @markdown\n",
    "# @markdown **Instructions:**\n",
    "# @markdown 1. Select dimensionality reduction methods\n",
    "# @markdown 2. Click **\"Generate ProtSpace JSON\"**\n",
    "# @markdown 3. Wait for `üéâ Generation and Styling Complete.` message (time varies with protein count)\n",
    "# @markdown 4. Continue to Step 6 or download files to upload at https://protspace.rostlab.org/\n",
    "# @markdown\n",
    "# @markdown **Note:** Uses data from Step 4. Re-run Step 4 if you change selections.\n",
    "# ---\n",
    "\n",
    "# --- Define Methods and Widgets ---\n",
    "dim_reduction_methods = [\n",
    "    (\"PCA 2D\", \"pca2\"),\n",
    "    (\"PCA 3D\", \"pca3\"),\n",
    "    (\"UMAP 2D\", \"umap2\"),\n",
    "    (\"UMAP 3D\", \"umap3\"),\n",
    "    (\"PaCMAP 2D\", \"pacmap2\"),\n",
    "    (\"PaCMAP 3D\", \"pacmap3\"),\n",
    "]\n",
    "method_checkboxes = [\n",
    "    Checkbox(description=name, value=(i % 2 == 0))  # Default to 2D methods\n",
    "    for i, (name, _) in enumerate(dim_reduction_methods)\n",
    "]\n",
    "\n",
    "# UMAP Parameters\n",
    "umap_n_neighbors = IntSlider(\n",
    "    value=25,\n",
    "    min=5,\n",
    "    max=200,\n",
    "    step=1,\n",
    "    description=\"n_neighbors:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "umap_min_dist = FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.01,\n",
    "    max=1,\n",
    "    step=0.01,\n",
    "    description=\"min_dist:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "\n",
    "# PaCMAP Parameters\n",
    "pacmap_mn_ratio = FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.1,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description=\"MN ratio:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "pacmap_fp_ratio = FloatSlider(\n",
    "    value=2.0,\n",
    "    min=0.1,\n",
    "    max=5.0,\n",
    "    step=0.1,\n",
    "    description=\"FP ratio:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "\n",
    "# Accordion for Parameters\n",
    "params_accordion = Accordion(\n",
    "    children=[\n",
    "        VBox([umap_n_neighbors, umap_min_dist]),\n",
    "        VBox([pacmap_mn_ratio, pacmap_fp_ratio]),\n",
    "    ]\n",
    ")\n",
    "params_accordion.set_title(0, \"UMAP Parameters\")\n",
    "params_accordion.set_title(1, \"PaCMAP Parameters\")\n",
    "params_accordion.selected_index = None  # Start collapsed\n",
    "\n",
    "# Buttons\n",
    "generate_button = Button(\n",
    "    description=\"Generate ProtSpace JSON\",\n",
    "    button_style=\"success\",\n",
    "    icon=\"check\",\n",
    "    layout=Layout(width=\"200px\"),\n",
    ")\n",
    "force_generate_button = Button(\n",
    "    description=\"Force Regenerate\",\n",
    "    button_style=\"warning\",\n",
    "    icon=\"refresh\",\n",
    "    layout=Layout(width=\"200px\"),\n",
    ")\n",
    "download_button = Button(\n",
    "    description=\"Download JSON\",\n",
    "    button_style=\"info\",\n",
    "    icon=\"download\",\n",
    "    layout=Layout(width=\"200px\"),\n",
    "    disabled=True,\n",
    ")\n",
    "gen_output = Output()\n",
    "\n",
    "\n",
    "# --- Styling Functions ---\n",
    "def _apply_styling_base(input_json_path: Path, csv_path: Path, style_logic_func):\n",
    "    \"\"\"Base function to read JSON, apply styling logic, and write styled JSON.\"\"\"\n",
    "    global generated_json_path  # Allow updating global state\n",
    "    if not input_json_path or not input_json_path.exists():\n",
    "        print(f\"‚ùå Error applying styling: Input JSON '{input_json_path}' not found.\")\n",
    "        generated_json_path = input_json_path if input_json_path else None  # Fallback\n",
    "        return None  # Indicate failure clearly\n",
    "    if not csv_path or not csv_path.exists():\n",
    "        print(f\"‚ùå Error applying styling: Metadata CSV '{csv_path}' not found.\")\n",
    "        generated_json_path = input_json_path  # Use unstyled if CSV missing\n",
    "        return input_json_path  # Return unstyled path\n",
    "\n",
    "    output_json_path = input_json_path.with_suffix(\".style.json\")\n",
    "\n",
    "    try:\n",
    "        # Define colors and shapes\n",
    "        # Ensure colormaps are accessed correctly\n",
    "        try:\n",
    "            tab20b = plt.get_cmap(\"tab20b\")\n",
    "            tab20c = plt.get_cmap(\"tab20c\")\n",
    "        except ValueError:\n",
    "            print(\n",
    "                \"‚ö†Ô∏è Warning: Colormaps 'tab20b' or 'tab20c' not found. Using fallback 'viridis'.\"\n",
    "            )\n",
    "            # Provide a fallback if specific maps aren't available (less likely with standard matplotlib)\n",
    "            tab20b = plt.get_cmap(\"viridis\")\n",
    "            tab20c = plt.get_cmap(\"plasma\")  # Different fallback\n",
    "\n",
    "        colors_b = [\n",
    "            to_hex(tab20b(i / 19.0)) for i in range(20)\n",
    "        ]  # Normalize index for colormap lookup\n",
    "        colors_c = [to_hex(tab20c(i / 19.0)) for i in range(20)]\n",
    "        all_colors = colors_b + colors_c  # 40 colors total\n",
    "        shapes = [\n",
    "            \"circle\",\n",
    "            \"square\",\n",
    "            \"diamond\",\n",
    "            \"cross\",\n",
    "            \"x\",\n",
    "            \"circle-open\",\n",
    "            \"square-open\",\n",
    "            \"diamond-open\",\n",
    "            \"triangle-up\",\n",
    "            \"star\",\n",
    "        ]  # 10 shapes\n",
    "\n",
    "        # Read metadata CSV\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Apply the specific styling logic\n",
    "        visualization_state = style_logic_func(df, all_colors, shapes)\n",
    "\n",
    "        if not visualization_state:  # Check if styling logic failed internally\n",
    "            raise ValueError(\"Styling logic function returned None or empty state.\")\n",
    "\n",
    "        # Read the original JSON data\n",
    "        with open(input_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Add visualization state\n",
    "        data[\"visualization_state\"] = visualization_state\n",
    "\n",
    "        # Write the updated (styled) JSON\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "        print(f\"‚úÖ Custom styling applied. Styled JSON saved to: {output_json_path}\")\n",
    "        generated_json_path = (\n",
    "            output_json_path  # Update global path to the styled version\n",
    "        )\n",
    "        return output_json_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error applying styling: {e}\")\n",
    "        print(\"   Proceeding with unstyled JSON.\")\n",
    "        generated_json_path = (\n",
    "            input_json_path  # Ensure global path points to the unstyled version\n",
    "        )\n",
    "        return input_json_path  # Return the original path as fallback\n",
    "\n",
    "\n",
    "def _pfam_style_logic(df, all_colors, shapes):\n",
    "    \"\"\"Generates Pfam-specific color/shape mapping.\"\"\"\n",
    "    # This function remains the same as previous version\n",
    "    if \"Pfam_Primary\" not in df.columns or \"Pfam_Extended\" not in df.columns:\n",
    "        print(\n",
    "            \"‚ùå Pfam styling error: Required columns ('Pfam_Primary', 'Pfam_Extended') not found in CSV.\"\n",
    "        )\n",
    "        return None\n",
    "    base_pfams = sorted(df[\"Pfam_Primary\"].dropna().unique().tolist())\n",
    "    num_base_pfams = len(base_pfams)\n",
    "    if num_base_pfams == 0:\n",
    "        return None\n",
    "    feature_colors = {\"Pfam_Primary\": {}, \"Pfam_Extended\": {}, \"Clan\": {}}\n",
    "    marker_shapes = {\"Pfam_Primary\": {}, \"Pfam_Extended\": {}, \"Clan\": {}}\n",
    "    clan_colors = {}\n",
    "    for i, base_pfam in enumerate(base_pfams):\n",
    "        current_shape = shapes[i % len(shapes)]\n",
    "        base_color_idx = (i * 4) % len(all_colors)\n",
    "        base_color = all_colors[base_color_idx]\n",
    "        feature_colors[\"Pfam_Primary\"][base_pfam] = base_color\n",
    "        marker_shapes[\"Pfam_Primary\"][base_pfam] = current_shape\n",
    "        feature_colors[\"Pfam_Extended\"][base_pfam] = base_color\n",
    "        marker_shapes[\"Pfam_Extended\"][base_pfam] = current_shape\n",
    "        variants = [\n",
    "            f\"{base_pfam} + 1 other\",\n",
    "            f\"{base_pfam} + 2 others\",\n",
    "            f\"{base_pfam} + >2 others\",\n",
    "        ]\n",
    "        unique_extended = df[\"Pfam_Extended\"].unique()\n",
    "        for j, variant in enumerate(variants):\n",
    "            if variant in unique_extended:\n",
    "                variant_color_idx = (base_color_idx + j + 1) % len(all_colors)\n",
    "                feature_colors[\"Pfam_Extended\"][variant] = all_colors[variant_color_idx]\n",
    "                marker_shapes[\"Pfam_Extended\"][variant] = current_shape\n",
    "        if \"Clan\" in df.columns:\n",
    "            clan_series = df.loc[df[\"Pfam_Primary\"] == base_pfam, \"Clan\"]\n",
    "            if not clan_series.empty:\n",
    "                clan = clan_series.iloc[0]\n",
    "                if pd.notna(clan) and clan != \"N/A\":\n",
    "                    if clan not in clan_colors:\n",
    "                        clan_colors[clan] = base_color\n",
    "                        feature_colors[\"Clan\"][clan] = base_color\n",
    "                        marker_shapes[\"Clan\"][clan] = current_shape\n",
    "                    else:\n",
    "                        feature_colors[\"Clan\"][clan] = clan_colors[clan]\n",
    "                        marker_shapes[\"Clan\"][clan] = current_shape\n",
    "    return {\"feature_colors\": feature_colors, \"marker_shapes\": marker_shapes}\n",
    "\n",
    "\n",
    "def _clan_style_logic(df, all_colors, shapes):\n",
    "    \"\"\"Generates Clan-specific color/shape mapping with corrected color logic.\"\"\"\n",
    "    # This function uses the corrected logic from the previous iteration\n",
    "    if \"Clan_Primary\" not in df.columns or \"Pfam_Label\" not in df.columns:\n",
    "        print(\n",
    "            \"‚ùå Clan styling error: Required columns ('Clan_Primary', 'Pfam_Label') not found in CSV.\"\n",
    "        )\n",
    "        return None\n",
    "    unique_clans = sorted(df[\"Clan_Primary\"].dropna().unique().tolist())\n",
    "    num_clans = len(unique_clans)\n",
    "    if num_clans == 0:\n",
    "        return None\n",
    "    feature_colors = {\"Clan_Primary\": {}, \"Pfam_Label\": {}}\n",
    "    marker_shapes = {\"Clan_Primary\": {}, \"Pfam_Label\": {}}\n",
    "    max_clans_to_style = 10\n",
    "    for i, clan in enumerate(unique_clans):\n",
    "        if i >= max_clans_to_style:\n",
    "            print(\n",
    "                f\"‚ö†Ô∏è Warning: More than {max_clans_to_style} clans selected. Styling might reuse colors/shapes for clans beyond the {max_clans_to_style}th.\"\n",
    "            )\n",
    "        current_shape = shapes[i % len(shapes)]\n",
    "        base_color_idx = (i * 4) % len(all_colors)\n",
    "        clan_color = all_colors[base_color_idx]\n",
    "        feature_colors[\"Clan_Primary\"][clan] = clan_color\n",
    "        marker_shapes[\"Clan_Primary\"][clan] = current_shape\n",
    "        clan_pfam_labels = sorted(\n",
    "            df[df[\"Clan_Primary\"] == clan][\"Pfam_Label\"].dropna().unique().tolist()\n",
    "        )\n",
    "        other_label = f\"{clan}: Other\"\n",
    "        color_offset = 1\n",
    "        # Assign colors to specific Pfam labels first\n",
    "        for pfam_label in clan_pfam_labels:\n",
    "            if pfam_label == other_label:\n",
    "                continue\n",
    "            if color_offset <= 2:  # Assign colors 1, 2 relative to base\n",
    "                label_color_idx = (base_color_idx + color_offset) % len(all_colors)\n",
    "                feature_colors[\"Pfam_Label\"][pfam_label] = all_colors[label_color_idx]\n",
    "                marker_shapes[\"Pfam_Label\"][pfam_label] = current_shape\n",
    "                color_offset += 1\n",
    "            else:  # Assign 'other' color (base+3) to any further specific Pfams\n",
    "                label_color_idx = (base_color_idx + 3) % len(all_colors)\n",
    "                feature_colors[\"Pfam_Label\"][pfam_label] = all_colors[label_color_idx]\n",
    "                marker_shapes[\"Pfam_Label\"][pfam_label] = current_shape\n",
    "        # Assign 'other' label color (base+3)\n",
    "        if other_label in clan_pfam_labels:\n",
    "            other_color_idx = (base_color_idx + 3) % len(all_colors)\n",
    "            feature_colors[\"Pfam_Label\"][other_label] = all_colors[other_color_idx]\n",
    "            marker_shapes[\"Pfam_Label\"][other_label] = current_shape\n",
    "    return {\"feature_colors\": feature_colors, \"marker_shapes\": marker_shapes}\n",
    "\n",
    "\n",
    "# --- Download Function ---\n",
    "def on_download_button_click(b):\n",
    "    \"\"\"Handles the download button click event.\"\"\"\n",
    "    if not generated_json_path or not generated_json_path.exists():\n",
    "        with gen_output:\n",
    "            print(\"‚ùå No valid JSON file available for download.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(generated_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_content = f.read()\n",
    "\n",
    "        # Create downloadable link\n",
    "        filename = generated_json_path.name\n",
    "        b64 = base64.b64encode(json_content.encode()).decode()\n",
    "        payload = f\"<a download='{filename}' href='data:application/json;base64,{b64}' target='_blank'>Click to download {filename}</a>\"\n",
    "\n",
    "        with gen_output:\n",
    "            clear_output()\n",
    "            print(f\"‚úÖ JSON file ready for download: {generated_json_path}\")\n",
    "            print(\"üì• Click the link below to download:\")\n",
    "            print(\"You can upload this file to https://protspace.rostlab.org/ for visualization.\")\n",
    "            display(HTML(payload))\n",
    "    except Exception as e:\n",
    "        with gen_output:\n",
    "            print(f\"‚ùå Error preparing download: {e}\")\n",
    "\n",
    "\n",
    "# --- Main Generation Function ---\n",
    "def run_protspace_generation(force=False):\n",
    "    \"\"\"Handles the logic for generating the ProtSpace JSON.\"\"\"\n",
    "    global generated_json_path  # Allow updating the global variable\n",
    "    download_button.disabled = (\n",
    "        True  # Disable download button until generation completes\n",
    "    )\n",
    "\n",
    "    with gen_output:\n",
    "        clear_output()\n",
    "        print(\"--- Starting ProtSpace JSON Generation ---\")\n",
    "\n",
    "        # 1. Get Selected Methods\n",
    "        selected_methods = [\n",
    "            method_code\n",
    "            for checkbox, (_, method_code) in zip(\n",
    "                method_checkboxes, dim_reduction_methods\n",
    "            )\n",
    "            if checkbox.value\n",
    "        ]\n",
    "        if not selected_methods:\n",
    "            print(\"‚ö†Ô∏è Please select at least one dimensionality reduction method.\")\n",
    "            return\n",
    "        print(f\"Selected methods: {', '.join(selected_methods)}\")\n",
    "\n",
    "        # 2. Check if Extraction was Run and Get Paths\n",
    "        if (\n",
    "            not last_extraction_dir\n",
    "            or not last_embedding_path\n",
    "            or not last_metadata_path\n",
    "            or not last_selection_mode\n",
    "            or not last_selected_items\n",
    "        ):\n",
    "            print(\n",
    "                \"‚ùå Error: Embedding extraction (Step 4) has not been run successfully for the current session, or its results are missing.\"\n",
    "            )\n",
    "            print(\"   Please run Step 4 for your desired selection first.\")\n",
    "            generated_json_path = None  # Ensure path is invalid\n",
    "            return\n",
    "\n",
    "        # --- Verify current selection matches last extraction ---\n",
    "        # current_mode is assumed global (from Cell 3)\n",
    "        current_selection_list = (\n",
    "            selected_pfams if current_mode == \"Pfam Families\" else selected_clans\n",
    "        )\n",
    "        if last_selection_mode != current_mode or set(last_selected_items) != set(\n",
    "            current_selection_list\n",
    "        ):\n",
    "            print(\n",
    "                \"‚ö†Ô∏è Warning: Your current selections in Step 3 do not match the data extracted in the last run of Step 4.\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Last extraction was for {last_selection_mode}: {', '.join(sorted(last_selected_items))}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Current selection is for {current_mode}: {', '.join(sorted(current_selection_list))}\"\n",
    "            )\n",
    "            print(\n",
    "                \"   Generation will proceed using the *previously extracted data*. If this is not intended, please re-run Step 4 with your current selections.\"\n",
    "            )\n",
    "        # --- End Check ---\n",
    "\n",
    "        embedding_path = last_embedding_path\n",
    "        metadata_path = last_metadata_path\n",
    "        output_dir = last_extraction_dir\n",
    "\n",
    "        # 3. Define Output JSON Paths using Pathlib\n",
    "        output_json_base = output_dir / \"protspace.json\"\n",
    "        styled_json_path = output_json_base.with_suffix(\".style.json\")\n",
    "\n",
    "        # 4. Check for Existing Files (Unless Force=True)\n",
    "        final_existing_path = None\n",
    "        if styled_json_path.exists():\n",
    "            final_existing_path = styled_json_path\n",
    "        elif output_json_base.exists():\n",
    "            final_existing_path = output_json_base\n",
    "\n",
    "        if final_existing_path and not force:\n",
    "            print(\"\\n‚ÑπÔ∏è ProtSpace JSON already exists for this selection:\")\n",
    "            print(f\"   {final_existing_path}\")\n",
    "            print(\"   Using existing file. To regenerate, click 'Force Regenerate'.\")\n",
    "            generated_json_path = final_existing_path  # Update global path\n",
    "            download_button.disabled = False  # Enable download button\n",
    "            print(\"\\nüéâ Ready for Step 6: Launch Visualization.\")\n",
    "            print(\n",
    "                \"   You can also download the JSON file to upload to https://protspace.rostlab.org/\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # 5. Build protspace-json Command (convert Paths to strings for subprocess)\n",
    "        cmd = [\n",
    "            \"protspace-json\",\n",
    "            \"-i\",\n",
    "            str(embedding_path),\n",
    "            \"-m\",\n",
    "            str(metadata_path),\n",
    "            \"-o\",\n",
    "            str(output_json_base),\n",
    "            \"--methods\",\n",
    "            *selected_methods,\n",
    "        ]\n",
    "        if any(m.startswith(\"umap\") for m in selected_methods):\n",
    "            cmd.extend(\n",
    "                [\n",
    "                    \"--n_neighbors\",\n",
    "                    str(umap_n_neighbors.value),\n",
    "                    \"--min_dist\",\n",
    "                    str(umap_min_dist.value),\n",
    "                ]\n",
    "            )\n",
    "        if any(m.startswith(\"pacmap\") for m in selected_methods):\n",
    "            cmd.extend(\n",
    "                [\n",
    "                    \"--mn_ratio\",\n",
    "                    str(pacmap_mn_ratio.value),\n",
    "                    \"--fp_ratio\",\n",
    "                    str(pacmap_fp_ratio.value),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # 6. Execute Command\n",
    "        print(\"\\nüîÑ Running protspace-json command...\")\n",
    "        try:\n",
    "            subprocess.run(\n",
    "                cmd, check=True, capture_output=True, text=True, encoding=\"utf-8\"\n",
    "            )\n",
    "            print(f\"‚úÖ Base ProtSpace JSON generated successfully: {output_json_base}\")\n",
    "\n",
    "            # 7. Apply Styling\n",
    "            print(\"\\nüîÑ Applying custom styling...\")\n",
    "            # Use the correct styling logic based on the *data that was processed*\n",
    "            style_logic = (\n",
    "                _pfam_style_logic\n",
    "                if last_selection_mode == \"Pfam Families\"\n",
    "                else _clan_style_logic\n",
    "            )\n",
    "            final_json_path = _apply_styling_base(\n",
    "                output_json_base, metadata_path, style_logic\n",
    "            )\n",
    "            # _apply_styling_base updates generated_json_path internally\n",
    "\n",
    "            if final_json_path and final_json_path.exists():\n",
    "                if final_json_path == styled_json_path:\n",
    "                    print(\"\\nüéâ Generation and Styling Complete.\")\n",
    "                else:\n",
    "                    print(\n",
    "                        \"\\n‚ö†Ô∏è Generation complete, but styling failed. Using unstyled JSON.\"\n",
    "                    )\n",
    "                print(f\"   Final JSON ready at: {generated_json_path}\")\n",
    "                download_button.disabled = False  # Enable download button\n",
    "                print(\"\\nReady for Step 6: Launch Visualization.\")\n",
    "                print(\n",
    "                    \"   You can also download the JSON file to upload to https://protspace.rostlab.org/\"\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    \"\\n‚ùå Generation failed or styling prevented file finalization. Check errors above.\"\n",
    "                )\n",
    "                generated_json_path = (\n",
    "                    None  # Ensure invalid path if styling failed badly\n",
    "                )\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\"‚ùå Error: 'protspace-json' command not found.\")\n",
    "            print(\n",
    "                \"   Please ensure ProtSpace is correctly installed in the environment.\"\n",
    "            )\n",
    "            generated_json_path = None\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(\n",
    "                f\"‚ùå Error running protspace-json command (return code {e.returncode}):\"\n",
    "            )\n",
    "            print(\"--- Command stdout ---\")\n",
    "            print(e.stdout)\n",
    "            print(\"--- Command stderr ---\")\n",
    "            print(e.stderr)\n",
    "            generated_json_path = None\n",
    "            if output_json_base.exists():\n",
    "                try:\n",
    "                    output_json_base.unlink(missing_ok=True)\n",
    "                except OSError:\n",
    "                    pass\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå An unexpected error occurred during generation: {e}\")\n",
    "            generated_json_path = None\n",
    "            if output_json_base.exists():\n",
    "                try:\n",
    "                    output_json_base.unlink(missing_ok=True)\n",
    "                except OSError:\n",
    "                    pass\n",
    "\n",
    "\n",
    "# --- Button Handlers ---\n",
    "def on_generate_click(b):\n",
    "    run_protspace_generation(force=False)\n",
    "\n",
    "\n",
    "def on_force_generate_click(b):\n",
    "    run_protspace_generation(force=True)\n",
    "\n",
    "\n",
    "# --- Connect Buttons ---\n",
    "generate_button.on_click(on_generate_click)\n",
    "force_generate_button.on_click(on_force_generate_click)\n",
    "download_button.on_click(on_download_button_click)\n",
    "\n",
    "# --- Display Widgets ---\n",
    "display(\n",
    "    VBox(\n",
    "        [\n",
    "            widgets.HTML(\"<b>Select dimensionality reduction methods:</b>\"),\n",
    "            widgets.VBox(method_checkboxes),\n",
    "            params_accordion,\n",
    "            HBox([generate_button, force_generate_button, download_button]),\n",
    "            gen_output,\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6422b5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @title 6. üöÄ Launch ProtSpace Visualization { display-mode: \"form\" }\n",
    "# @markdown Configure and launch ProtSpace visualization.\n",
    "# @markdown\n",
    "# @markdown **Instructions:**\n",
    "# @markdown 1. Enter JSON file path or leave empty to use last generated file\n",
    "# @markdown 2. Adjust height\n",
    "# @markdown 3. Select display mode: `inline` or `external` (external mode works only with Chrome)\n",
    "# @markdown 4. Click **\"Launch ProtSpace\"**\n",
    "# @markdown\n",
    "# @markdown ---\n",
    "\n",
    "# --- Widget Definitions ---\n",
    "json_file_input = Text(\n",
    "    value=\"\",  # Start empty - will use last generated file if left empty\n",
    "    placeholder=\"Leave empty to use last generated file, or enter path to JSON file\",\n",
    "    description=\"JSON File:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"90%\"),\n",
    ")\n",
    "height_slider = IntSlider(\n",
    "    value=800,\n",
    "    min=400,\n",
    "    max=1200,\n",
    "    step=50,\n",
    "    description=\"Height (px):\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"50%\"),\n",
    ")\n",
    "# Removed 'jupyterlab' from options\n",
    "mode_dropdown = Dropdown(\n",
    "    options=[\"inline\", \"external\"],\n",
    "    value=\"inline\",\n",
    "    description=\"Display Mode:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=Layout(width=\"50%\"),\n",
    ")\n",
    "launch_button = Button(\n",
    "    description=\"Launch ProtSpace\", button_style=\"primary\", icon=\"rocket\"\n",
    ")\n",
    "launch_output = Output()\n",
    "\n",
    "\n",
    "# --- Launch Handler ---\n",
    "def on_launch_button_click(b):\n",
    "    \"\"\"Handles the launch button click event.\"\"\"\n",
    "    with launch_output:\n",
    "        clear_output()\n",
    "\n",
    "        # 1. Determine JSON file path (use user input or fall back to generated_json_path)\n",
    "        json_file_str = json_file_input.value.strip()\n",
    "        if not json_file_str:\n",
    "            # Use the global generated_json_path if available\n",
    "            global generated_json_path\n",
    "            if generated_json_path is not None:\n",
    "                json_file_str = str(generated_json_path)\n",
    "                print(f\"‚ÑπÔ∏è Using generated JSON file: {json_file_str}\")\n",
    "            else:\n",
    "                print(\n",
    "                    \"‚ùå Error: Please enter the path to the ProtSpace JSON file generated in Step 5.\"\n",
    "                )\n",
    "                return\n",
    "\n",
    "        json_file = Path(json_file_str)\n",
    "        if not json_file.exists():\n",
    "            print(f\"‚ùå Error: Specified JSON file not found at '{json_file}'.\")\n",
    "            print(\"   Please ensure the path is correct and the file exists.\")\n",
    "            return\n",
    "        # Verify it's likely a JSON file\n",
    "        if not (json_file.suffix == \".json\"):\n",
    "            print(\n",
    "                f\"‚ö†Ô∏è Warning: The specified file '{json_file.name}' does not have a .json extension. Proceeding anyway.\"\n",
    "            )\n",
    "\n",
    "        # 2. Get Parameters\n",
    "        height = height_slider.value\n",
    "        mode = mode_dropdown.value\n",
    "        port = 8051  # Fixed port\n",
    "\n",
    "        # 3. Display Launch Info\n",
    "        launch_info_html = f\"\"\"\n",
    "        <div style=\"border: 1px solid #ccc; background-color: #dddddd; padding: 10px; margin-bottom: 15px; border-radius: 4px; color: black;\">\n",
    "            <h4 style=\"margin-top: 0; color: black;\">üöÄ Launching ProtSpace...</h4>\n",
    "            <ul style=\"color: black;\">\n",
    "                <li><b>File:</b> {json_file}</li>\n",
    "                <li><b>Mode:</b> {mode}</li>\n",
    "                {\"<li><b>Height:</b> \" + str(height) + \"px</li>\" if mode == \"inline\" else \"\"}\n",
    "                {'<li><b>URL:</b> <a href=\"http://127.0.0.1:' + str(port) + '\" target=\"_blank\" style=\"color: blue;\">http://127.0.0.1:' + str(port) + \"</a></li>\" if mode in [\"tab\", \"external\"] else \"\"}\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(launch_info_html))\n",
    "\n",
    "        # 4. Launch ProtSpace App\n",
    "        try:\n",
    "            protspace_instance = ProtSpace(default_json_file=str(json_file))\n",
    "            app = protspace_instance.create_app()\n",
    "\n",
    "            if mode == \"inline\":\n",
    "                print(\"üîÑ Loading visualization in 'inline' mode...\")\n",
    "                app.run(\n",
    "                    port=port,\n",
    "                    jupyter_mode=mode,\n",
    "                    jupyter_height=height,\n",
    "                    jupyter_width=\"100%\",\n",
    "                    dev_tools_silence_routes_logging=True,\n",
    "                    dev_tools_prune_errors=True,\n",
    "                )\n",
    "            elif mode == \"external\":\n",
    "                print(\"üîÑ Starting server for 'external' mode...\")\n",
    "                print(\"‚ö†Ô∏è Note: External mode works only with Google Chrome.\")\n",
    "                original_stdout, original_stderr = sys.stdout, sys.stderr\n",
    "                sys.stdout = sys.stderr = open(os.devnull, 'w')\n",
    "                app.run(\n",
    "                    port=port,\n",
    "                    jupyter_mode=mode,\n",
    "                    debug=False,\n",
    "                    dev_tools_silence_routes_logging=True,\n",
    "                    dev_tools_prune_errors=True,\n",
    "                    serve_kernel_port_as_iframe=True,\n",
    "                )\n",
    "                sys.stdout, sys.stderr = original_stdout, original_stderr\n",
    "                print(f\"‚úÖ Server running at http://127.0.0.1:{port}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Error: Unknown display mode '{mode}'.\")\n",
    "\n",
    "        except ImportError as e:\n",
    "            if \"werkzeug\" in str(e).lower():\n",
    "                print(\"‚ùå Error: A dependency issue occurred (likely with 'werkzeug').\")\n",
    "                print(\n",
    "                    \"   Consider installing a specific version via pip if problems persist: pip install werkzeug==2.3.7\"\n",
    "                )\n",
    "            else:\n",
    "                print(f\"‚ùå An import error occurred: {e}\")\n",
    "                print(\n",
    "                    \"   Please ensure all dependencies from Step 1 are installed correctly.\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå An unexpected error occurred while launching ProtSpace: {e}\")\n",
    "            print(\"--- Traceback ---\")\n",
    "            print(traceback.format_exc())\n",
    "\n",
    "\n",
    "# --- Connect Button ---\n",
    "launch_button.on_click(on_launch_button_click)\n",
    "\n",
    "# --- Display Widgets ---\n",
    "display(\n",
    "    VBox(\n",
    "        [\n",
    "            widgets.HTML(\"<h3>üöÄ Visualization Settings</h3>\"),\n",
    "            json_file_input,\n",
    "            HBox([height_slider, mode_dropdown]),\n",
    "            launch_button,\n",
    "            launch_output,\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7bc3d",
   "metadata": {},
   "source": [
    "---\n",
    "## üß† Tips for Exploring the Visualization\n",
    "\n",
    "Once the ProtSpace visualization loads:\n",
    "\n",
    "* **Navigation:** Switch between projection methods (PCA, UMAP, etc.) using the \"Method\" dropdown\n",
    "* **Interaction:**\n",
    "  * Hover over points to see details\n",
    "  * Use lasso/box tools to select groups of points\n",
    "  * Zoom/pan with mouse wheel or toolbar\n",
    "  * Search for specific proteins in the search box\n",
    "\n",
    "### Interpreting Results\n",
    "\n",
    "*   **Clustering:** Proteins from the same Pfam family or clan often cluster together, indicating similarity in their embedding space (which often relates to sequence/functional similarity).\n",
    "*   **Multi-Domain Proteins:** Proteins belonging to multiple families (e.g., those labeled \"+ N others\" in Pfam mode) might appear between clusters or in unexpected locations.\n",
    "*   **Clan Structure:** In Clan mode, coloring by \"Pfam_Label\" can reveal how different Pfam families within the same clan are distributed relative to each other. The styling attempts to use similar color tones for Pfams belonging to the same clan. Using the same shape for all points within a clan (by selecting \"Clan_Primary\" for Shape) helps visually group them.\n",
    "*   **Projection Methods:** PCA shows global patterns; UMAP/PaCMAP reveal local structures\n",
    "\n",
    "### Iterating Your Analysis\n",
    "\n",
    "*   **Step 3:** Return to Step 3 to select different Pfam families/clans\n",
    "*   **Step 4:** Re-run extraction\n",
    "*   **Step 5:** Regenerate visualization JSON\n",
    "*   **Step 6:** Launch new visualization with updated JSON path\n",
    "\n",
    "Happy exploring! üåå"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
